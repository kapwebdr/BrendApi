API BRENDA - Documentation des Endpoints
======================================

Configuration CORS
----------------
L'API accepte les requêtes de toutes les origines (CORS activé) avec :
- Toutes les origines autorisées (*)
- Toutes les méthodes HTTP autorisées
- Tous les headers autorisés
- Support des credentials
- Tous les headers exposés

1. Liste des Modèles
-------------------
Endpoint : GET /v1/models
Description : Récupère la liste des modèles disponibles
Retour : 
{
    "models": ["Vigogne-2-13B", "CodeLlama-13B", "Llama-2-13B", ...]
}

2. Chargement d'un Modèle
------------------------
Endpoint : POST /v1/models/{model_name}/load
Paramètres URL :
- model_name : Nom du modèle à charger (string)

Retour : Stream d'événements SSE (text/event-stream)
Événements possibles :
- {"progress": 0.45}            // Progression du téléchargement (0 à 1)
- {"status": "exists"}          // Si le modèle existe déjà
- {"status": "completed"}       // Téléchargement terminé
- {"status": "loaded"}          // Modèle chargé avec succès
- {"error": "message d'erreur"} // En cas d'erreur

3. Chat Completions
------------------
Endpoint : POST /v1/chat/completions
Content-Type : application/json

Corps de la requête :
{
    "model": string,        // Nom du modèle à utiliser
    "messages": [           // Historique des messages
        {
            "role": string, // "system", "user", "assistant" ou "ai"
            "content": string
        }
    ],
    "stream": boolean,      // Mode streaming (optionnel, défaut: false)
    "system": string       // Message système pour cette requête
}

Notes sur le système :
- Le message système est fourni dans chaque requête
- Il remplace tout message système précédent
- Si non fourni, utilise un message système par défaut

Retours possibles :

A. Mode non-streaming (stream: false)
Content-Type : application/json
{
    "choices": [
        {
            "message": {
                "role": "assistant",
                "content": string
            }
        }
    ]
}

B. Mode streaming (stream: true)
Content-Type : text/event-stream
Format : 
data: {chunk de texte}
data: {chunk de texte}
...
data: [DONE]

Codes d'erreur :
- 400 : Aucun modèle n'est chargé
- 404 : Modèle non trouvé
- 500 : Erreur interne du serveur

Notes :
-------
- Les modèles sont téléchargés depuis Hugging Face automatiquement si nécessaire
- Le streaming est compatible avec le format des événements SSE
- L'API est conçue pour être compatible avec l'API OpenAI
- Les modèles sont stockés dans le dossier Cache/LlamaCppModel
- Les configurations des modèles sont stockées dans models.json

Gestion des Sessions
------------------
L'API utilise un header X-Session-ID pour gérer les sessions :
- Si le header X-Session-ID n'est pas fourni, un nouveau ID de session est généré
- Si le header X-Session-ID est fourni, la session existante est utilisée
- L'ID de session est retourné dans le header X-Session-ID de chaque réponse
- Les clients doivent stocker cet ID et le renvoyer dans les requêtes suivantes

Exemple d'utilisation :
1. Première requête : pas de X-Session-ID envoyé -> nouveau ID généré et retourné
2. Requêtes suivantes : envoyer le X-Session-ID reçu dans le header
3. L'API maintient l'état de la session (modèle chargé, etc.) tant que le même ID est utilisé

4. État de la Session
-------------------
Endpoint : GET /v1/session
Description : Récupère l'état actuel de la session
Retour :
{
    "session_id": string,
    "current_model": string | null,
    "has_model_loaded": boolean
}

5. Arrêt de la Génération
------------------------
Endpoint : POST /v1/stop
Description : Arrête la génération en cours pour la session

Headers requis :
- X-Session-ID : ID de la session pour laquelle arrêter la génération

Retour :
Content-Type : application/json
{
    "status": "stopped"
}

Codes d'erreur :
- 400 : Aucun modèle n'est chargé pour cette session
- 500 : Erreur lors de l'arrêt de la génération

Notes :
- L'arrêt est immédiat
- La session reste valide et peut être réutilisée pour de nouvelles requêtes
- L'historique de la conversation est conservé

6. Génération et Analyse d'Images
--------------------------------

Format des Images :
Pour tous les endpoints qui nécessitent une image en entrée, l'image doit être envoyée en base64.
Format attendu : "data:image/png;base64,{base64_string}" ou directement la chaîne base64.

6.1 Génération d'Images
----------------------
Endpoint : POST /v1/images/generate
Content-Type : application/json

Corps de la requête :
{
    "model_type": string,     // Type de modèle (défaut: "sdxl-turbo")
    "prompt": string,         // Description de l'image à générer
    "negative_prompt": string, // Prompt négatif (optionnel)
    "width": integer,         // Largeur de l'image (optionnel, défaut: 1024)
    "height": integer,        // Hauteur de l'image (optionnel, défaut: 1024)
    "steps": integer          // Nombre d'étapes de génération (optionnel, défaut: 20)
}

Retour : Stream d'événements SSE
Événements possibles :
- {"progress": 0.45}       // Progression de la génération (0 à 1)
- {"status": "completed", "image": "base64..."} // Image générée en base64
- {"error": "message"}     // En cas d'erreur

6.2 Liste des Modèles d'Images
----------------------------
Endpoint : GET /v1/images/models
Description : Liste les modèles de génération d'images disponibles

Retour :
{
    "models": ["sdxl-turbo", "sdxl-base", ...]
}

6.3 Analyse d'Image (CLIP)
------------------------
Endpoint : POST /v1/images/analyze
Content-Type : application/json

Corps de la requête :
{
    "image": string,     // Image en base64
    "labels": [string]   // Liste des labels à vérifier
}

Exemple :
{
    "image": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...",
    "labels": ["chat", "chien", "oiseau"]
}

6.4 OCR (Extraction de Texte)
---------------------------
Endpoint : POST /v1/images/ocr
Content-Type : application/json

Corps de la requête :
{
    "image": string  // Image en base64
}

6.5 Raffinement d'Image
----------------------
Endpoint : POST /v1/images/refine
Content-Type : application/json

Corps de la requête :
{
    "image": string,         // Image source en base64
    "prompt": string,        // Description pour le raffinement
    "negative_prompt": string, // Prompt négatif (optionnel)
    "strength": float,       // Force du raffinement (0-1, défaut: 0.3)
    "steps": integer         // Nombre d'étapes (optionnel, défaut: 20)
}

Notes sur la Gestion des Images :
-------------------------------
- Toutes les images doivent être envoyées en base64
- Format accepté : "data:image/png;base64,..." ou chaîne base64 pure
- Taille maximale recommandée : 10MB
- Formats d'image supportés : PNG, JPEG, WebP
- Les images générées sont toujours retournées en base64 (PNG)

Exemple de conversion côté client (JavaScript) :

7. Traduction
------------

7.1 Liste des Langues
-------------------
Endpoint : GET /v1/translation/languages
Description : Récupère la liste des langues disponibles pour la traduction

Retour :
{
    "languages": {
        "en": ["fr", "es", "de", "it"],
        "fr": ["en", "es", "de", "it"],
        ...
    }
}

7.2 Traduction de Texte
---------------------
Endpoint : POST /v1/translation/translate
Content-Type : application/json

Corps de la requête :
{
    "text": string,      // Texte à traduire
    "from_lang": string, // Langue source (ex: "en")
    "to_lang": string    // Langue cible (ex: "fr")
}

Retour :
{
    "translated_text": string, // Texte traduit
    "from": string,           // Langue source
    "to": string             // Langue cible
}

Notes sur la Traduction :
- Utilise les modèles Helsinki-NLP
- Les modèles sont chargés à la demande et mis en cache
- Supporte plusieurs paires de langues
- Les codes de langue suivent le format ISO (ex: "en", "fr", "es")

8. Monitoring Système
-------------------
Endpoint : WebSocket /ws/system-metrics
Description : Fournit en temps réel les métriques système (CPU, mémoire, GPU)

Format des données :
{
    "cpu": {
        "percent": float,          // Pourcentage d'utilisation CPU
        "frequency_current": float, // Fréquence actuelle en MHz
        "frequency_max": float,     // Fréquence maximale en MHz
        "cores": int               // Nombre de cœurs
    },
    "memory": {
        "total": float,      // Mémoire totale en GB
        "available": float,  // Mémoire disponible en GB
        "percent": float,    // Pourcentage d'utilisation
        "used": float       // Mémoire utilisée en GB
    },
    "gpu": [                // Liste des GPUs (vide si pas de GPU)
        {
            "id": int,           // ID du GPU
            "name": string,      // Nom du GPU
            "load": float,       // Charge en pourcentage
            "memory_used": float, // Mémoire utilisée en MB
            "memory_total": float, // Mémoire totale en MB
            "temperature": float  // Température en °C
        }
    ]
}

Notes sur le Monitoring :
- Les données sont mises à jour toutes les secondes
- La connexion WebSocket reste active jusqu'à ce que le client se déconnecte
- Les métriques GPU ne sont disponibles que si un GPU compatible est détecté
- Utilise psutil pour les métriques CPU/RAM et GPUtil pour les métriques GPU

Interface Web :
- Une interface de visualisation est disponible dans /templates/system_monitor.html
- Affiche des graphiques en temps réel pour CPU, mémoire et GPU
- Utilise Plotly.js pour la visualisation
- Les graphiques se mettent à jour automatiquement

Exemple d'utilisation WebSocket (JavaScript) :

9. Endpoint AI Unifié
-------------------
Endpoint : POST /v1/ai/process
Description : Interface unifiée pour tous les outils d'IA
Content-Type : application/json

Corps de la requête :
{
    "tool": string,    // Type d'outil à utiliser
    "config": object   // Configuration spécifique à l'outil
}

Types d'outils disponibles (tool) :
- "llm" : Modèle de langage
- "image_generation" : Génération d'images
- "image_refinement" : Raffinement d'images
- "image_analysis" : Analyse d'images
- "ocr" : Reconnaissance de texte
- "translation" : Traduction

Configurations spécifiques par outil :

A. LLM (tool: "llm")
{
    "model": string,        // Nom du modèle à utiliser
    "messages": [           // Historique des messages
        {
            "role": string, // "system", "user", "assistant"
            "content": string
        }
    ],
    "stream": boolean,      // Mode streaming (optionnel)
    "system": string       // Message système (optionnel)
}

B. Génération d'Image (tool: "image_generation")
{
    "model_type": string,      // Type de modèle (défaut: "sdxl/turbo")
    "prompt": string,          // Description de l'image
    "negative_prompt": string, // Prompt négatif (optionnel)
    "width": integer,         // Largeur (optionnel, défaut: 1024)
    "height": integer,        // Hauteur (optionnel, défaut: 1024)
    "steps": integer          // Étapes (optionnel, défaut: 20)
}

C. Raffinement d'Image (tool: "image_refinement")
{
    "image": string,          // Image source en base64
    "prompt": string,         // Description pour le raffinement
    "negative_prompt": string, // Prompt négatif (optionnel)
    "strength": float,        // Force du raffinement (optionnel, défaut: 0.3)
    "steps": integer          // Étapes (optionnel, défaut: 20)
}

D. Analyse d'Image (tool: "image_analysis")
{
    "image": string,     // Image en base64
    "labels": [string]   // Liste des labels à vérifier
}

E. OCR (tool: "ocr")
{
    "image": string      // Image en base64
}

F. Traduction (tool: "translation")
{
    "text": string,      // Texte à traduire
    "from_lang": string, // Langue source
    "to_lang": string    // Langue cible
}

Codes d'erreur :
- 400 : Configuration invalide ou manquante
- 404 : Ressource non trouvée (ex: modèle)
- 500 : Erreur interne du serveur

Notes :
- L'endpoint gère automatiquement la validation des configurations
- Le header X-Session-ID est géré comme pour les autres endpoints
- Les réponses conservent le même format que les endpoints spécifiques
- Le streaming est supporté pour les outils compatibles (LLM, génération d'images)

Exemple d'utilisation :

10. Outils Audio
--------------
Les outils audio sont accessibles via l'endpoint unifié /v1/ai/process avec les tools suivants :

A. Text-to-Speech (tool: "text_to_speech")
----------------------------------------
Configuration :
{
    "text": string,          // Texte à convertir en audio
    "voice_path": string,    // Chemin vers le fichier voix (optionnel)
    "language": string       // Code langue (optionnel, défaut: "fr")
}

Retour : Stream d'événements SSE
- {"progress": float}                    // Progression (0-100)
- {"status": "completed",                // Audio généré
   "audio": "base64_string",            // Audio en base64
   "sample_rate": int}                  // Taux d'échantillonnage
- {"error": "message d'erreur"}         // En cas d'erreur

B. Speech-to-Text (tool: "speech_to_text")
----------------------------------------
Configuration :
{
    "audio": string         // Audio en base64
}

Retour :
{
    "text": string,         // Texte transcrit
    "language": string,     // Langue détectée
    "segments": [           // Segments de transcription
        {
            "text": string,
            "start": float, // Temps de début en secondes
            "end": float    // Temps de fin en secondes
        }
    ]
}

C. Liste des Modèles Audio (tool: "list_speech_models")
---------------------------------------------------
Configuration : {}  // Aucune configuration requise

Retour :
{
    "models": {
        "tts": {
            "xtts_v2": {
                "name": "XTTS v2",
                "languages": ["fr", "en", "es", ...]
            }
        },
        "stt": {
            "whisper": {
                "name": "Faster Whisper",
                "sizes": ["tiny", "base", "small", "medium", "large-v3"]
            }
        }
    }
}

Notes sur les Outils Audio :
- Les modèles sont chargés automatiquement à la demande
- Le streaming est supporté pour la synthèse vocale (TTS)
- Les fichiers audio ne sont pas sauvegardés sur le disque
- Support des formats audio courants (WAV)
- Détection automatique du matériel (CPU/GPU/MPS)

11. Outils HTTP et Extraction Web
------------------------------
Les outils HTTP sont accessibles via l'endpoint unifié /v1/ai/process avec les tools suivants :

A. Analyse d'URL (tool: "url_analyze")
-----------------------------------
Configuration :
{
    "url": string           // URL à analyser
}

Retour :
{
    "url": string,          // URL analysée
    "domain": string,       // Domaine
    "path": string,         // Chemin
    "content_type": string, // Type de contenu
    "size": integer,        // Taille en octets
    "headers": object,      // Headers HTTP
    "status": integer       // Code status HTTP
}

B. Extraction de Contenu (tool: "url_extract")
------------------------------------------
Configuration :
{
    "url": string,           // URL source
    "selectors": [string]    // Liste des sélecteurs CSS (optionnel)
}

Retour : Stream d'événements SSE
- {"selector": "css_selector", "content": "contenu extrait"}  // Pour chaque sélecteur
- {"content": "texte complet"}                                // Sans sélecteur
- {"error": "message d'erreur"}                              // En cas d'erreur

C. Streaming de Contenu (tool: "url_stream")
----------------------------------------
Configuration :
{
    "url": string          // URL du contenu à streamer
}

Retour : Stream d'événements SSE
- {"progress": float,                    // Progression (0-100)
   "chunk": "base64_data",              // Chunk de données encodé en base64
   "content_type": "type_mime"}         // Type de contenu
- {"status": "completed"}               // Streaming terminé
- {"error": "message d'erreur"}         // En cas d'erreur

D. Streaming YouTube (tool: "youtube_stream")
-----------------------------------------
Configuration :
{
    "video_id": string      // ID de la vidéo YouTube
}

Retour : Stream d'événements SSE
- {"title": string,                      // Titre de la vidéo
   "author": string,                     // Auteur
   "length": integer}                    // Durée en secondes
- {"progress": float,                    // Progression (0-100)
   "chunk": "base64_data",              // Chunk vidéo encodé en base64
   "content_type": "video/mp4"}         // Type de contenu
- {"status": "completed"}               // Streaming terminé
- {"error": "message d'erreur"}         // En cas d'erreur

Notes sur les Outils HTTP :
- Tous les contenus sont streamés en chunks et encodés en base64
- Aucune sauvegarde locale des fichiers
- Support de multiples types de contenu (HTML, JSON, vidéo, etc.)
- Extraction sélective de contenu HTML via sélecteurs CSS
- Progression en temps réel pour tous les streams
- Gestion automatique des erreurs et timeouts

Exemple d'utilisation de streaming :

E. Métriques Système (tool: "system_metrics")
-----------------------------------------
Configuration : {}  // Aucune configuration requise

Retour :
{
    "cpu": {
        "percent": float,          // Pourcentage d'utilisation CPU
        "frequency_current": float, // Fréquence actuelle en MHz
        "frequency_max": float,     // Fréquence maximale en MHz
        "cores": int               // Nombre de cœurs
    },
    "memory": {
        "total": float,      // Mémoire totale en GB
        "available": float,  // Mémoire disponible en GB
        "percent": float,    // Pourcentage d'utilisation
        "used": float       // Mémoire utilisée en GB
    },
    "gpu": [                // Liste des GPUs (vide si pas de GPU)
        {
            "id": int,           // ID du GPU
            "name": string,      // Nom du GPU
            "load": float,       // Charge en pourcentage
            "memory_used": float, // Mémoire utilisée en MB
            "memory_total": float, // Mémoire totale en MB
            "temperature": float  // Température en °C
        }
    ]
}

Exemple d'utilisation :
